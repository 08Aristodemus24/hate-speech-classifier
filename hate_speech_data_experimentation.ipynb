{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from utilities.data_preprocessors import simple_preprocess, preprocess, re_encode_targets\n",
    "from utilities.data_loaders import load_data\n",
    "from utilities.data_visualizers import view_sentence\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load datasets hate-offensive-speech, slur-corupus, ethos, reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframes\n",
    "tweets = load_data('./data/hate-speech-and-offensive-language/hate-offensive-speech.csv')\n",
    "slurs = load_data('./data/slur-corpus/kurrek.2020.slur-corpus.csv', 'slur-corpus')\n",
    "\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['class'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slurs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets['class'].unique())\n",
    "print(slurs['gold_label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets['class'].value_counts())\n",
    "print(slurs['gold_label'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data with nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_idxs = np.where(slurs['gold_label'].isnull())[0]\n",
    "nan_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slurs.iloc[nan_idxs]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some rows with nans in gold_label have significant slur words attached to the comment so replace gold_label with DEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slurs['body'] = slurs['body'].astype('str')\n",
    "slurs['gold_label'] = slurs['gold_label'].astype('str')\n",
    "\n",
    "# manually change gold_label of relevant comments to one of the classes DEG, NDG, HOM, CMP, and APR\n",
    "slurs.loc[[5733, 31815], 'gold_label'] = 'DEG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(slurs.loc[5734, 'body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(slurs.loc[5734, 'gold_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slurs.iloc[nan_idxs]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### since all gold_label with nans and with significant slurs attached to them have been modified drop the rest of the rows with both nan in comment and in gold_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify rows with both nan in comment or label\n",
    "nan_rows = np.where((slurs['gold_label'] == 'nan') | (slurs['body'] == 'nan'))[0]\n",
    "nan_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with nan in comment or label\n",
    "slurs.drop(nan_rows, inplace=True)\n",
    "slurs.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_idxs_new = np.where(slurs['gold_label'].isnull())[0]\n",
    "slurs.iloc[nan_idxs_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(slurs['gold_label'].unique())\n",
    "print(slurs['gold_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slurs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess text\n",
    "- remove trailing whitespaces\n",
    "- remove non-alphanumeric characters\n",
    "- lower sentences\n",
    "- tokenize\n",
    "- remove stop words\n",
    "- lemmatize or stem word\n",
    "- encode target column to numbers\n",
    "\n",
    "<u>or use gensim.utils.simple_preprocess as callback of self.apply()</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tweet'] = tweets['tweet'].apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tweet'] = tweets['tweet'].apply(simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slurs['body'] = slurs['body'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_sentence(slurs['body'], limit=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slurs['body'] = slurs['body'].apply(simple_preprocess)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode target/y labels/outputs/columns of the slur dataset\n",
    "- recall that it has the ff labels and its respective counts\n",
    "- ['DEG' 'NDG' 'HOM' 'CMP' 'APR']\n",
    "- DEG    20532\n",
    "- NDG    16727\n",
    "- HOM     1998\n",
    "- APR      553\n",
    "- CMP      189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  encoding labels to numbers in slur dataset\n",
    "encoder = LabelEncoder()\n",
    "slurs['gold_label'] = encoder.fit_transform(slurs['gold_label'])\n",
    "print(slurs['gold_label'].unique())\n",
    "print(slurs['gold_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slurs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary:\n",
    "- DEG has label 2, NDG has label 4, HOM has label 3, APR has label 0, and CMP has label 1\n",
    "- encode noise labels to just non-derogatory label instead which is 4\n",
    "- or encode non-derogatory label to 1 and just think of 1 as now the non-derogatory label instead of noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slurs[slurs['gold_label'] == 4] = 1\n",
    "print(slurs['gold_label'].unique())\n",
    "print(slurs['gold_label'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## re-encode labels of hate tweet dataset\n",
    "- hate class currently 0 can be lumped in with derogatory class of slur dataset, so encode to 2\n",
    "- offensive class currently 1 can be lumped in with appropriative class of slur dataset, so encode to 0\n",
    "- neither class currently 2 can be lumped in with non derogatory of slur dataset, so encode to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['class'] = tweets['class'].apply(re_encode_targets)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.loc[0, 'tweet']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rename columns of both slur and tweet datasets and combine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split input/independent and output/dependent columns/features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hate-speech-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
