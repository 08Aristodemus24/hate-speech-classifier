{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to train and validate the softmax classifier as to compare its performance to that of an LSTM neural network for hate speech classification\n",
    "\n",
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import one_hot\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from utilities.data_preprocessors import read_preprocess, series_to_1D_array, construct_embedding_dict, construct_embedding_matrix, sentences_to_avgs\n",
    "from utilities.data_visualizers import train_cross_results_v2, view_final_metrics\n",
    "from models.softmax_regression import SoftmaxRegression\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 for religious and 0 for non religious\n",
    "df = pd.read_csv('./data/hate-speech-data-cleaned.csv', index_col=0)\n",
    "df = read_preprocess(df)\n",
    "\n",
    "all_words = pd.Series(series_to_1D_array(df['comment']))\n",
    "all_unique_words_counts = all_words.value_counts()\n",
    "all_unique_words = all_words.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    22395\n",
       "1    21644\n",
       "0    19743\n",
       "3     1998\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>woman complain cleaning house man always take ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boy dat coldtyga dwn bad cuffin dat hoe st place</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dawg ever fuck bitch start cry confused shit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>look like tranny</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shit hear might true might faker bitch told ya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65775</th>\n",
       "      <td>from the midnight sun where the hot spring blow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65776</th>\n",
       "      <td>do not say am not your type</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65777</th>\n",
       "      <td>and therefor never send to know for whom the b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65778</th>\n",
       "      <td>and cannot stand anoth day</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65779</th>\n",
       "      <td>all valu unless otherwis state are in american...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65780 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  label\n",
       "0      woman complain cleaning house man always take ...      1\n",
       "1       boy dat coldtyga dwn bad cuffin dat hoe st place      0\n",
       "2           dawg ever fuck bitch start cry confused shit      0\n",
       "3                                       look like tranny      0\n",
       "4         shit hear might true might faker bitch told ya      0\n",
       "...                                                  ...    ...\n",
       "65775    from the midnight sun where the hot spring blow      1\n",
       "65776                        do not say am not your type      1\n",
       "65777  and therefor never send to know for whom the b...      1\n",
       "65778                         and cannot stand anoth day      1\n",
       "65779  all valu unless otherwis state are in american...      1\n",
       "\n",
       "[65780 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rejoin the comment columns values of lists of words to sentences\n",
    "df['comment'] = df['comment'].apply(lambda comment: \" \".join(comment))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# at the same time one hot encode the y labels/classes\n",
    "len_unique_labels = len(df['label'].unique())\n",
    "Y_oh = one_hot(df['label'], len_unique_labels, dtype=tf.float64).numpy()\n",
    "Y_oh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving and assigning important variables for training classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47916\n"
     ]
    }
   ],
   "source": [
    "sents = df['comment']\n",
    "\n",
    "# get number of all unique words\n",
    "num_words_3 = len(all_unique_words)\n",
    "\n",
    "# instantiate Tokenizer on the total number of all unique words\n",
    "tokenizer = Tokenizer(num_words=num_words_3, split=' ')\n",
    "\n",
    "# call .fit_on_texts to create the word_index and index_word dicts\n",
    "tokenizer.fit_on_texts(sents)\n",
    "\n",
    "# save the tokenizer dictionaries for use later when loading GloVe embeddings\n",
    "word_to_index = tokenizer.word_index\n",
    "index_to_word = tokenizer.index_word\n",
    "print(len(word_to_index))\n",
    "# print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47916/47916 [00:00<00:00, 269351.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# important variables\n",
    "\n",
    "# includes oov words\n",
    "emb_dict, emb_vec_len = construct_embedding_dict('./embeddings/glove.42B.300d.txt', word_to_index)\n",
    "emb_matrix = construct_embedding_matrix(word_to_index, emb_dict, emb_vec_len)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform all sentences to word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_sents = sentences_to_avgs(sents, emb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00396263,  0.36776125, -0.04045763, ..., -0.06078575,\n",
       "         0.09397175, -0.05599563],\n",
       "       [ 0.29468613,  0.39194278,  0.03957122, ..., -0.03101056,\n",
       "         0.32691778,  0.10542444],\n",
       "       [-0.30736394,  0.26374987, -0.06718987, ...,  0.0969691 ,\n",
       "         0.08005263,  0.15465625],\n",
       "       ...,\n",
       "       [-0.152688  , -0.13310289, -0.10236191, ..., -0.16498182,\n",
       "        -0.04798355,  0.04919357],\n",
       "       [-0.0755652 ,  0.0974086 ,  0.1262868 , ..., -0.073394  ,\n",
       "        -0.1070248 ,  0.246028  ],\n",
       "       [ 0.009189  ,  0.167159  ,  0.03203911, ..., -0.15171311,\n",
       "         0.11298801, -0.13568356]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65780, 300)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_sents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65780, 4)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training, validation, adn testing\n",
    "train_seqs, _seqs, train_labels, _labels = train_test_split(vect_sents, Y_oh, test_size=0.3, random_state=0)\n",
    "val_seqs, test_seqs, val_labels, test_labels = train_test_split(_seqs, _labels, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_oh.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_sents.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 - train_loss: 254244.5064182826 - train_categorical_accuracy: 260.17% - val_loss: 75879.82981532066 - val_categorical_accuracy: 259.55%\n",
      "epoch 500 - train_loss: 25879.10220086981 - train_categorical_accuracy: 357.64% - val_loss: 8078.804382746674 - val_categorical_accuracy: 356.37%\n",
      "epoch 1000 - train_loss: 25458.374878070055 - train_categorical_accuracy: 358.42% - val_loss: 7968.616298859404 - val_categorical_accuracy: 356.64%\n",
      "epoch 1500 - train_loss: 25385.00621553114 - train_categorical_accuracy: 358.49% - val_loss: 7957.885047411175 - val_categorical_accuracy: 356.53%\n",
      "epoch 2000 - train_loss: 25360.931675678738 - train_categorical_accuracy: 358.46% - val_loss: 7955.820314496204 - val_categorical_accuracy: 356.37%\n",
      "epoch 2500 - train_loss: 25349.31416943556 - train_categorical_accuracy: 358.52% - val_loss: 7955.625863436393 - val_categorical_accuracy: 356.43%\n",
      "epoch 3000 - train_loss: 25342.825444153375 - train_categorical_accuracy: 358.47% - val_loss: 7956.628806431749 - val_categorical_accuracy: 356.46%\n",
      "epoch 3500 - train_loss: 25339.320597778988 - train_categorical_accuracy: 358.43% - val_loss: 7958.153418414868 - val_categorical_accuracy: 356.55%\n",
      "epoch 4000 - train_loss: 25337.5641721636 - train_categorical_accuracy: 358.42% - val_loss: 7959.58511626974 - val_categorical_accuracy: 356.59%\n",
      "epoch 4500 - train_loss: 25336.733274499595 - train_categorical_accuracy: 358.42% - val_loss: 7960.656469846494 - val_categorical_accuracy: 356.53%\n",
      "epoch 4999 - train_loss: 25336.339332578817 - train_categorical_accuracy: 358.39% - val_loss: 7961.332440953212 - val_categorical_accuracy: 356.56%\n"
     ]
    }
   ],
   "source": [
    "model = SoftmaxRegression(train_seqs, train_labels, val_seqs, val_labels, lambda_=0.7)\n",
    "softmax_history = model.train(show_vars=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dictionary of results based on metric history of both models\n",
    "softmax_results = {}\n",
    "for metric in ['train_loss', 'train_categorical_accuracy', 'val_loss', 'val_categorical_accuracy']:\n",
    "    if metric not in softmax_results:\n",
    "        softmax_results[metric] = softmax_history.history[metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cross_results_v2(softmax_results, epochs=softmax_history.epoch[-1], img_title='softmax regression classifier results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display values from last epoch of baseline model\n",
    "view_final_metrics(softmax_results, 'SOFTMAX REGRESSION CLASSIFIER RESULTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 1. 0. 0.], shape=(4,), dtype=float32)\n",
      "[0. 1. 0. 0.]\n",
      "Accuracy: 0.779260\n",
      "Precision: 0.779260\n",
      "Recall: 0.785077\n",
      "F1 score: 0.791209\n"
     ]
    }
   ],
   "source": [
    "# bug of accuracy precision recall and f1 score being all athe same: https://stackoverflow.com/questions/62792001/precision-and-recall-are-the-same-within-a-model\n",
    "# Looking at the documentation for these scores, it appears like they should all come out the same when you are using 'micro'.\n",
    "\n",
    "# They are all counting the fraction of times that you get the correct label.\n",
    "\n",
    "# See the examples:\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html\n",
    "\n",
    "# In fact in the last three they all give the same example and of course get the same score.\n",
    "# https://stackoverflow.com/questions/31421413/how-to-compute-precision-recall-accuracy-and-f1-score-for-the-multiclass-case\n",
    "# https://machinelearningmastery.com/precision-recall-and-f-measure-for-imbalanced-classification/\n",
    "\n",
    "\n",
    "# predict probabilities for test set\n",
    "Y_pred = model.predict(test_seqs)\n",
    "print(Y_pred[0])\n",
    "print(test_labels[0])\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(test_labels, Y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(test_labels, Y_pred, average='micro')\n",
    "print('Precision: %f' % precision)\n",
    "\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(test_labels, Y_pred, average='macro')\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(test_labels, Y_pred, average='macro')\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "# matrix = confusion_matrix(test_labels, Y_pred)\n",
    "# print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hate-speech-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
