{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to train and validate the softmax classifier as to compare its performance to that of an LSTM neural network for hate speech classification\n",
    "\n",
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import one_hot\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from utilities.data_preprocessors import read_preprocess, series_to_1D_array, construct_embedding_dict, construct_embedding_matrix, sentences_to_avgs\n",
    "from utilities.data_visualizers import train_cross_results_v2, view_final_metrics\n",
    "from models.softmax_regression import SoftmaxRegression\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 for religious and 0 for non religious\n",
    "df = pd.read_csv('./data/hate-speech-data-cleaned.csv', index_col=0)\n",
    "df = read_preprocess(df)\n",
    "\n",
    "all_words = pd.Series(series_to_1D_array(df['comment']))\n",
    "all_unique_words_counts = all_words.value_counts()\n",
    "all_unique_words = all_words.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    22395\n",
       "1    21644\n",
       "0    19743\n",
       "3     1998\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>woman complain cleaning house man always take ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boy dat coldtyga dwn bad cuffin dat hoe st place</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dawg ever fuck bitch start cry confused shit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>look like tranny</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shit hear might true might faker bitch told ya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65775</th>\n",
       "      <td>from the midnight sun where the hot spring blow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65776</th>\n",
       "      <td>do not say am not your type</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65777</th>\n",
       "      <td>and therefor never send to know for whom the b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65778</th>\n",
       "      <td>and cannot stand anoth day</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65779</th>\n",
       "      <td>all valu unless otherwis state are in american...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65780 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  label\n",
       "0      woman complain cleaning house man always take ...      1\n",
       "1       boy dat coldtyga dwn bad cuffin dat hoe st place      0\n",
       "2           dawg ever fuck bitch start cry confused shit      0\n",
       "3                                       look like tranny      0\n",
       "4         shit hear might true might faker bitch told ya      0\n",
       "...                                                  ...    ...\n",
       "65775    from the midnight sun where the hot spring blow      1\n",
       "65776                        do not say am not your type      1\n",
       "65777  and therefor never send to know for whom the b...      1\n",
       "65778                         and cannot stand anoth day      1\n",
       "65779  all valu unless otherwis state are in american...      1\n",
       "\n",
       "[65780 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rejoin the comment columns values of lists of words to sentences\n",
    "df['comment'] = df['comment'].apply(lambda comment: \" \".join(comment))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# at the same time one hot encode the y labels/classes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m len_unique_labels \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(df[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique())\n\u001b[1;32m----> 3\u001b[0m Y_oh \u001b[39m=\u001b[39m one_hot(df[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m], len_unique_labels, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat64)\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m      4\u001b[0m Y_oh\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# at the same time one hot encode the y labels/classes\n",
    "len_unique_labels = len(df['label'].unique())\n",
    "Y_oh = one_hot(df['label'], len_unique_labels, dtype=tf.float64).numpy()\n",
    "Y_oh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving and assigning important variables for training classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47916\n"
     ]
    }
   ],
   "source": [
    "sents = df['comment']\n",
    "\n",
    "# get number of all unique words\n",
    "num_words_3 = len(all_unique_words)\n",
    "\n",
    "# instantiate Tokenizer on the total number of all unique words\n",
    "tokenizer = Tokenizer(num_words=num_words_3, split=' ')\n",
    "\n",
    "# call .fit_on_texts to create the word_index and index_word dicts\n",
    "tokenizer.fit_on_texts(sents)\n",
    "\n",
    "# save the tokenizer dictionaries for use later when loading GloVe embeddings\n",
    "word_to_index = tokenizer.word_index\n",
    "index_to_word = tokenizer.index_word\n",
    "print(len(word_to_index))\n",
    "# print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47916/47916 [00:00<00:00, 273974.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# important variables\n",
    "\n",
    "# includes oov words\n",
    "emb_dict, emb_vec_len = construct_embedding_dict('./embeddings/glove.42B.300d.txt', word_to_index)\n",
    "emb_matrix = construct_embedding_matrix(word_to_index, emb_dict, emb_vec_len)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform all sentences to word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_sents = sentences_to_avgs(sents, emb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00396263,  0.36776125, -0.04045763, ..., -0.06078575,\n",
       "         0.09397175, -0.05599563],\n",
       "       [ 0.29468613,  0.39194278,  0.03957122, ..., -0.03101056,\n",
       "         0.32691778,  0.10542444],\n",
       "       [-0.30736394,  0.26374987, -0.06718987, ...,  0.0969691 ,\n",
       "         0.08005263,  0.15465625],\n",
       "       ...,\n",
       "       [-0.152688  , -0.13310289, -0.10236191, ..., -0.16498182,\n",
       "        -0.04798355,  0.04919357],\n",
       "       [-0.0755652 ,  0.0974086 ,  0.1262868 , ..., -0.073394  ,\n",
       "        -0.1070248 ,  0.246028  ],\n",
       "       [ 0.009189  ,  0.167159  ,  0.03203911, ..., -0.15171311,\n",
       "         0.11298801, -0.13568356]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65780, 300)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_sents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65780, 4)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training, validation, adn testing\n",
    "train_seqs, _seqs, train_labels, _labels = train_test_split(vect_sents, Y_oh, test_size=0.3, random_state=0)\n",
    "val_seqs, test_seqs, val_labels, test_labels = train_test_split(_seqs, _labels, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_oh.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_sents.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "initial_value: Tensor conversion requested dtype float64 for Tensor with dtype float32: <tf.Tensor: shape=(4, 1), dtype=float32, numpy=\narray([[0.],\n       [0.],\n       [0.],\n       [0.]], dtype=float32)>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[39m=\u001b[39m SoftmaxRegression(train_seqs\u001b[39m.\u001b[39mT, train_labels\u001b[39m.\u001b[39mT)\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32md:\\Projects\\To Github\\hate-speech-classifier\\models\\softmax_regression.py:49\u001b[0m, in \u001b[0;36mSoftmaxRegression.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39m# initializer parameters e.g. because X is (nf x m) and Y is\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39m# (nc x m) theta is (nc x nf) and beta is (nc x 1)\u001b[39;00m\n\u001b[0;32m     48\u001b[0m THETA \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mVariable(tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(shape\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features), dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat64))\n\u001b[1;32m---> 49\u001b[0m BETA \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mVariable(tf\u001b[39m.\u001b[39;49mzeros(shape\u001b[39m=\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_classes, \u001b[39m1\u001b[39;49m)), dtype\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mfloat64)\n\u001b[0;32m     51\u001b[0m \u001b[39m# initialize optimizer\u001b[39;00m\n\u001b[0;32m     52\u001b[0m optimizer \u001b[39m=\u001b[39m Adam(learning_rate\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearning_rate)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\hate-speech-classifier\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\hate-speech-classifier\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1603\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1601\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, Tensor):\n\u001b[0;32m   1602\u001b[0m   \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m dtype\u001b[39m.\u001b[39mis_compatible_with(value\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m-> 1603\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1604\u001b[0m         _add_error_prefix(\n\u001b[0;32m   1605\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTensor conversion requested dtype \u001b[39m\u001b[39m{\u001b[39;00mdtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1606\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfor Tensor with dtype \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1607\u001b[0m             name\u001b[39m=\u001b[39mname))\n\u001b[0;32m   1608\u001b[0m   \u001b[39mreturn\u001b[39;00m value\n\u001b[0;32m   1610\u001b[0m \u001b[39mif\u001b[39;00m preferred_dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: initial_value: Tensor conversion requested dtype float64 for Tensor with dtype float32: <tf.Tensor: shape=(4, 1), dtype=float32, numpy=\narray([[0.],\n       [0.],\n       [0.],\n       [0.]], dtype=float32)>"
     ]
    }
   ],
   "source": [
    "model = SoftmaxRegression(train_seqs.T, train_labels.T)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # predict probabilities for test set\n",
    "# yhat_probs = model.predict(testX, verbose=0)\n",
    "# # predict crisp classes for test set\n",
    "# yhat_classes = model.predict_classes(testX, verbose=0)\n",
    "\n",
    "# # reduce to 1d array\n",
    "# yhat_probs = yhat_probs[:, 0]\n",
    "# yhat_classes = yhat_classes[:, 0]\n",
    "\n",
    "# # accuracy: (tp + tn) / (p + n)\n",
    "# accuracy = accuracy_score(testy, yhat_classes)\n",
    "# print('Accuracy: %f' % accuracy)\n",
    "# # precision tp / (tp + fp)\n",
    "# precision = precision_score(testy, yhat_classes)\n",
    "# print('Precision: %f' % precision)\n",
    "# # recall: tp / (tp + fn)\n",
    "# recall = recall_score(testy, yhat_classes)\n",
    "# print('Recall: %f' % recall)\n",
    "# # f1: 2 tp / (2 tp + fp + fn)\n",
    "# f1 = f1_score(testy, yhat_classes)\n",
    "# print('F1 score: %f' % f1)\n",
    "\n",
    "# matrix = confusion_matrix(testy, yhat_classes)\n",
    "# print(matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hate-speech-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
