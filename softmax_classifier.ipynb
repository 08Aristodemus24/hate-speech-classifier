{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to train and validate the softmax classifier as to compare its performance to that of an LSTM neural network for hate speech classification\n",
    "\n",
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import one_hot\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from utilities.data_preprocessors import read_preprocess, series_to_1D_array, construct_embedding_dict, construct_embedding_matrix, sentences_to_avgs\n",
    "from utilities.data_visualizers import train_cross_results_v2, view_final_metrics\n",
    "from models.softmax_regression import SoftmaxRegression\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 for religious and 0 for non religious\n",
    "df = pd.read_csv('./data/hate-speech-data-cleaned.csv', index_col=0)\n",
    "df = read_preprocess(df)\n",
    "\n",
    "all_words = pd.Series(series_to_1D_array(df['comment']))\n",
    "all_unique_words_counts = all_words.value_counts()\n",
    "all_unique_words = all_words.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    22395\n",
       "1    21644\n",
       "0    19743\n",
       "3     1998\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>woman complain cleaning house man always take ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boy dat coldtyga dwn bad cuffin dat hoe st place</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dawg ever fuck bitch start cry confused shit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>look like tranny</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shit hear might true might faker bitch told ya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65775</th>\n",
       "      <td>from the midnight sun where the hot spring blow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65776</th>\n",
       "      <td>do not say am not your type</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65777</th>\n",
       "      <td>and therefor never send to know for whom the b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65778</th>\n",
       "      <td>and cannot stand anoth day</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65779</th>\n",
       "      <td>all valu unless otherwis state are in american...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65780 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  label\n",
       "0      woman complain cleaning house man always take ...      1\n",
       "1       boy dat coldtyga dwn bad cuffin dat hoe st place      0\n",
       "2           dawg ever fuck bitch start cry confused shit      0\n",
       "3                                       look like tranny      0\n",
       "4         shit hear might true might faker bitch told ya      0\n",
       "...                                                  ...    ...\n",
       "65775    from the midnight sun where the hot spring blow      1\n",
       "65776                        do not say am not your type      1\n",
       "65777  and therefor never send to know for whom the b...      1\n",
       "65778                         and cannot stand anoth day      1\n",
       "65779  all valu unless otherwis state are in american...      1\n",
       "\n",
       "[65780 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rejoin the comment columns values of lists of words to sentences\n",
    "df['comment'] = df['comment'].apply(lambda comment: \" \".join(comment))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# at the same time one hot encode the y labels/classes\n",
    "len_unique_labels = len(df['label'].unique())\n",
    "Y_oh = one_hot(df['label'], len_unique_labels, dtype=tf.float64).numpy()\n",
    "Y_oh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving and assigning important variables for training classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47916\n"
     ]
    }
   ],
   "source": [
    "sents = df['comment']\n",
    "\n",
    "# get number of all unique words\n",
    "num_words_3 = len(all_unique_words)\n",
    "\n",
    "# instantiate Tokenizer on the total number of all unique words\n",
    "tokenizer = Tokenizer(num_words=num_words_3, split=' ')\n",
    "\n",
    "# call .fit_on_texts to create the word_index and index_word dicts\n",
    "tokenizer.fit_on_texts(sents)\n",
    "\n",
    "# save the tokenizer dictionaries for use later when loading GloVe embeddings\n",
    "word_to_index = tokenizer.word_index\n",
    "index_to_word = tokenizer.index_word\n",
    "print(len(word_to_index))\n",
    "# print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47916/47916 [00:00<00:00, 275444.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# important variables\n",
    "\n",
    "# includes oov words\n",
    "emb_dict, emb_vec_len = construct_embedding_dict('./embeddings/glove.42B.300d.txt', word_to_index)\n",
    "emb_matrix = construct_embedding_matrix(word_to_index, emb_dict, emb_vec_len)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform all sentences to word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_sents = sentences_to_avgs(sents, emb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00396263,  0.36776125, -0.04045763, ..., -0.06078575,\n",
       "         0.09397175, -0.05599563],\n",
       "       [ 0.29468613,  0.39194278,  0.03957122, ..., -0.03101056,\n",
       "         0.32691778,  0.10542444],\n",
       "       [-0.30736394,  0.26374987, -0.06718987, ...,  0.0969691 ,\n",
       "         0.08005263,  0.15465625],\n",
       "       ...,\n",
       "       [-0.152688  , -0.13310289, -0.10236191, ..., -0.16498182,\n",
       "        -0.04798355,  0.04919357],\n",
       "       [-0.0755652 ,  0.0974086 ,  0.1262868 , ..., -0.073394  ,\n",
       "        -0.1070248 ,  0.246028  ],\n",
       "       [ 0.009189  ,  0.167159  ,  0.03203911, ..., -0.15171311,\n",
       "         0.11298801, -0.13568356]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65780, 300)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_sents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65780, 4)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training, validation, adn testing\n",
    "train_seqs, _seqs, train_labels, _labels = train_test_split(vect_sents, Y_oh, test_size=0.3, random_state=0)\n",
    "val_seqs, test_seqs, val_labels, test_labels = train_test_split(_seqs, _labels, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_oh.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_sents.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training cost at epoch 0: 138524.96480023087 \t validation cost at epoch 0: 41291.527477024836\n",
      "\n",
      "training cost at epoch 500: 25533.894002108358 \t validation cost at epoch 500: 7978.982541709377\n",
      "\n",
      "training cost at epoch 1000: 25360.18086397874 \t validation cost at epoch 1000: 7948.391943650553\n",
      "\n",
      "training cost at epoch 1500: 25340.885050039382 \t validation cost at epoch 1500: 7954.812453966636\n",
      "\n",
      "training cost at epoch 2000: 25337.01134623006 \t validation cost at epoch 2000: 7958.9835712623\n",
      "\n",
      "training cost at epoch 2500: 25336.098137851277 \t validation cost at epoch 2500: 7960.957243083528\n",
      "\n",
      "training cost at epoch 3000: 25335.86783441338 \t validation cost at epoch 3000: 7961.766715493408\n",
      "\n",
      "training cost at epoch 3500: 25335.81366512102 \t validation cost at epoch 3500: 7962.05764678692\n",
      "\n",
      "training cost at epoch 4000: 25335.802472748906 \t validation cost at epoch 4000: 7962.153583926802\n",
      "\n",
      "training cost at epoch 4500: 25337.119396088063 \t validation cost at epoch 4500: 7961.497040967139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SoftmaxRegression(train_seqs, train_labels, val_seqs, val_labels, lambda_=0.7)\n",
    "model.train(show_vars=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 1. 0. 0.], shape=(4,), dtype=float32)\n",
      "[0. 1. 0. 0.]\n",
      "Accuracy: 0.778754\n",
      "Precision: 0.778754\n",
      "Recall: 0.778754\n",
      "F1 score: 0.778754\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m f1 \u001b[39m=\u001b[39m f1_score(test_labels, Y_pred, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmicro\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mF1 score: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m f1)\n\u001b[1;32m---> 22\u001b[0m matrix \u001b[39m=\u001b[39m confusion_matrix(test_labels, Y_pred)\n\u001b[0;32m     23\u001b[0m \u001b[39mprint\u001b[39m(matrix)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\hate-speech-classifier\\lib\\site-packages\\sklearn\\metrics\\_classification.py:319\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    317\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    318\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n\u001b[0;32m    321\u001b[0m \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    322\u001b[0m     labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "\u001b[1;31mValueError\u001b[0m: multilabel-indicator is not supported"
     ]
    }
   ],
   "source": [
    "# bug of accuracy precision recall and f1 score being all athe same: https://stackoverflow.com/questions/62792001/precision-and-recall-are-the-same-within-a-model\n",
    "\n",
    "\n",
    "# predict probabilities for test set\n",
    "Y_pred = model.predict(test_seqs)\n",
    "print(Y_pred[0])\n",
    "print(test_labels[0])\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(test_labels, Y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(test_labels, Y_pred, average='micro')\n",
    "print('Precision: %f' % precision)\n",
    "\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(test_labels, Y_pred, average='micro')\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(test_labels, Y_pred, average='micro')\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "matrix = confusion_matrix(test_labels, Y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hate-speech-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
