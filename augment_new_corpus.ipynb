{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from mittens import GloVe, Mittens\n",
    "\n",
    "from utilities.data_loaders import load_co_occ_matrix, view_and_load_data, glove2dict\n",
    "from utilities.data_preprocessors import rejoin_data\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_new_embeddings(pre_glove, oov_vocab, co_occ_matrix, dim=300, epochs=1000):\n",
    "    \"\"\"\n",
    "    Training the Mittens model with the new words\n",
    "    * since our GloVe word embeddings are basically 300 in length our n \n",
    "    arg here should be also 300 we also set max_iter or our number of \n",
    "    epochs to train our word embedding model to maybe 1000 to 5000 epochs\n",
    "    \"\"\"\n",
    "\n",
    "    # instantiate the Mittens class\n",
    "    mittens_model = Mittens(n=dim, max_iter=epochs)\n",
    "\n",
    "    # this will return only the words not existing in our pre-trained word embeddings\n",
    "    # but the good thing is we can reshape adn save this file to resemble that of our\n",
    "    # pretrained word embeddings file\n",
    "    new_embeddings = mittens_model.fit(\n",
    "        co_occ_matrix,\n",
    "        vocab=oov_vocab,\n",
    "        initial_embedding_dict=pre_glove\n",
    "    )\n",
    "\n",
    "    post_glove = dict(zip(oov_vocab, new_embeddings))\n",
    "    \n",
    "    with open(\"./embeddings/hate_speech_glove.txt\",\"wb\") as file:\n",
    "        pickle.dump(post_glove, file)\n",
    "        file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load pre glove and create OOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cleaned dataset\n",
    "data_path = './data/hate-speech-data-cleaned.csv'\n",
    "df_1, all_words, all_unique_words, all_unique_words_counts = view_and_load_data(data_path)\n",
    "\n",
    "# here all tokens/words are joined to form a list of all\n",
    "# the joined words or the sentences themselves which on\n",
    "# the whole is the document\n",
    "df_2 = rejoin_data(df_1)\n",
    "\n",
    "# Get all words not occuring in the pre-trained word embeddings\n",
    "# in this important phase we will have to get all words not \n",
    "# occuring in the dictionary we have of the words and their \n",
    "# already existing embeddings. We also generate an important \n",
    "# matrix called the co-occurence matrix in order to train our\n",
    "# word embedding model with the use of the existign weights/embeddings \n",
    "# of GloVes dictionary to unseen words in our hate speech dataset\n",
    "pre_glove = glove2dict('./embeddings/glove.42B.300d.txt')\n",
    "\n",
    "# get all the words in our current corpus that is not \n",
    "# in our dictionary of words and their respective embeddings\n",
    "oov = [token for token in all_unique_words if token not in pre_glove.keys()]\n",
    "oov_vocab = list(set(oov))\n",
    "print(f'list of words not in glove: \\n{oov_vocab}\\n')\n",
    "print(f'length of OOV words: {len(oov_vocab)}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load co-occurence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved co-occurence matrix\n",
    "co_occ_path = \"./embeddings/hate_co_occ_matrix.txt\"\n",
    "co_occ_matrix = load_co_occ_matrix(co_occ_path)\n",
    "print(f'the co-occurence matrix: \\n{co_occ_matrix}\\n')\n",
    "print(f'shape of the co-occurence matrix: {co_occ_matrix.shape}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Mittens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_embeddings(pre_glove, oov_vocab, co_occ_matrix)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
